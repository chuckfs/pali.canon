# pali.canon

Canon-grounded Q&A over the TheravÄda PÄli Canon â€” fully local, private, and citation-based.
Pipeline: LLM â†’ RAG â†’ LLM (planner â†’ retriever â†’ synthesizer), powered by Ollama + Chroma.

âš¡ No API keys, no cloud calls â€” runs entirely on your computer.


## âœ¨ Features
- OCR-first indexing (indexer.py)
Every page of every Canon PDF becomes searchable (stored in ocr_cache/).
- Structured planning (planner.py)
Parses IDs like SN 35.28 and infers context (Sutta / Vinaya / Abhidhamma).
- Accurate retrieval (retriever.py)
Uses nomic-embed-text embeddings + MMR search for diverse, relevant results.
- Grounded synthesis (synthesizer.py)
Local Mistral model via Ollama generates neutral, citation-rich answers.
	- Dual interface:
ğŸ§  Command-line (pali) â€” fast and scriptable.
ğŸ’¬ Gradio web app (app.py) â€” chat-style experience.


## ğŸ—‚ Repo layout

pali.canon/
â”œâ”€ data/
â”‚  â””â”€ pali_canon/          # your Canon PDFs
â”œâ”€ ocr_cache/              # OCRâ€™d copies (auto-created)
â”œâ”€ .env                    # environment variables
â”œâ”€ app.py                  # Gradio app (LLMâ†’RAGâ†’LLM)
â”œâ”€ cli.py                  # command-line interface
â”œâ”€ config.py               # loads env vars
â”œâ”€ indexer.py              # OCR + page-level indexer
â”œâ”€ planner.py              # query planner
â”œâ”€ retriever.py            # search engine
â”œâ”€ synthesizer.py          # grounded answer generator
â””â”€ requirements.txt



## ğŸš€ Quickstart

### 0) Prereqs

ğŸ Python 3.10+

ğŸ¦™ Ollama (local LLM host)

brew install --cask ollama
brew services start ollama
ollama pull mistral
ollama pull nomic-embed-text

ğŸ§¾ OCR tools

brew install ocrmypdf mupdf

ğŸ“¦ Git LFS (for PDFs)

git lfs install



### 1) Create your virtual environment

cd ~/pali.canon
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt



### 2) Environment setup

In ~/.zshrc (already done if you cloned from this repo):

# ğŸª· Pali Canon environment variables
export PALI_PROJECT_ROOT="$HOME/pali.canon"
export PALI_CHROMA_DIR="$PALI_PROJECT_ROOT/chroma"
export PALI_CHROMA_COLLECTION="pali_canon"
export PALI_EMBED_MODEL="nomic-embed-text"

Then add the magic shortcut:

hello() {
  if [[ "$1" == "pali" ]]; then
    echo ""
    echo "ğŸª· Welcome back to pali.canon, Charlie (or future scholar)."
    echo "Activating virtual environment..."
    cd ~/pali.canon || return
    source .venv/bin/activate
    echo ""
    echo "ğŸ“˜ Ready. Try:"
    echo "   pali \"What is the Fire Sermon?\""
    echo ""
  else
    echo "Usage: hello pali"
  fi
}

Reload your shell:

source ~/.zshrc



### 3) Build the index (one-time OCR)

hello pali
python indexer.py

This creates the searchable Chroma database and caches OCRâ€™d pages under ocr_cache/.


### 4) Ask questions â€” two ways

ğŸ§  CLI

pali "What is the Fire Sermon?"

ğŸ’¬ Gradio UI

python app.py

Open the printed local URL (e.g., http://127.0.0.1:7860).


## ğŸ’¡ Examples

pali "What does the Buddha say about craving?"
pali "Explain the simile of the saw."
pali "Where is the KÄlÄma Sutta found?"

Each response cites the exact PDF + page (e.g., samyutta_nikaya1.pdf â€” p.112).


## âš™ï¸ Config knobs

Variable	Default	Description
PALI_LLM_MODEL	mistral	Ollama LLM for synthesis
PALI_EMBED_MODEL	nomic-embed-text	embedding model
PALI_CHROMA_COLLECTION	pali_canon	Chroma collection name
TOP_K	8	chunks to pass downstream
RAG_MIN_NEEDED	4	widen search if fewer hits



## ğŸ§˜â€â™‚ï¸ Troubleshooting
- Ollama connection failed â†’ brew services start ollama
- Empty answers? â†’ re-run python indexer.py
- No .venv? â†’ recreate it:
python3 -m venv .venv && source .venv/bin/activate
- Show hidden files: âŒ˜ + Shift + .


## ğŸ›  Advanced
- Auto-activate: hello pali moves to ~/pali.canon and activates .venv.
- Rebuild index anytime: python indexer.py
- Update everything + push:

git add -A
git commit -m "update pipeline"
git push origin main




## ğŸ“œ License

Apache-2.0 â€” see LICENSE


## ğŸ™ Acknowledgments
- Community translators and editors of the PÄli Canon
- Open-source projects powering this stack: Ollama, Chroma, LangChain, PyMuPDF, rapidfuzz


hello pali
pali "What is the Fire Sermon?"
